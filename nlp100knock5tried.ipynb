{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pydotplus\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surface: 先生,base: 先生,pos: 名詞,pos1: 一般\n",
      "surface: は,base: は,pos: 助詞,pos1: 係助詞\n",
      "surface: これら,base: これら,pos: 名詞,pos1: 代名詞\n",
      "surface: の,base: の,pos: 助詞,pos1: 連体化\n",
      "surface: 墓標,base: 墓標,pos: 名詞,pos1: 一般\n",
      "surface: が,base: が,pos: 助詞,pos1: 格助詞\n",
      "surface: 現,base: 現,pos: 接頭詞,pos1: 名詞接続\n",
      "surface: わす,base: わする,pos: 動詞,pos1: 自立\n",
      "surface: 人種,base: 人種,pos: 名詞,pos1: 一般\n",
      "surface: 々,base: 々,pos: 記号,pos1: 一般\n",
      "surface: の,base: の,pos: 助詞,pos1: 連体化\n",
      "surface: 様式,base: 様式,pos: 名詞,pos1: 一般\n",
      "surface: に対して,base: に対して,pos: 助詞,pos1: 格助詞\n",
      "surface: 、,base: 、,pos: 記号,pos1: 読点\n",
      "surface: 私,base: 私,pos: 名詞,pos1: 代名詞\n",
      "surface: ほど,base: ほど,pos: 助詞,pos1: 副助詞\n",
      "surface: に,base: に,pos: 助詞,pos1: 格助詞\n",
      "surface: 滑稽,base: 滑稽,pos: 名詞,pos1: 一般\n",
      "surface: も,base: も,pos: 助詞,pos1: 係助詞\n",
      "surface: アイロニー,base: アイロニー,pos: 名詞,pos1: 一般\n",
      "surface: も,base: も,pos: 助詞,pos1: 係助詞\n",
      "surface: 認め,base: 認める,pos: 動詞,pos1: 自立\n",
      "surface: て,base: てる,pos: 動詞,pos1: 非自立\n",
      "surface: ない,base: ない,pos: 助動詞,pos1: *\n",
      "surface: らしかっ,base: らしい,pos: 助動詞,pos1: *\n",
      "surface: た,base: た,pos: 助動詞,pos1: *\n",
      "surface: 。,base: 。,pos: 記号,pos1: 句点\n"
     ]
    }
   ],
   "source": [
    "class Morph:\n",
    "    def __init__(self,surface,base,pos,pos1):\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1\n",
    "    def is_end_of_sentence(self):\n",
    "        return self.pos1 == '句点'\n",
    "    def __str__(self):\n",
    "        return 'surface: {},base: {},pos: {},pos1: {}'.format(self.surface,\\\n",
    "                                            self.base, self.pos, self.pos1)\n",
    "def make_morph_list(analyzed_file_name: str) -> list:\n",
    "    \"\"\"\n",
    "    係り受けした文章ファイル→[[1文morphオブジェクト],[1文morphオブジェクト]...]\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    with open(analyzed_file_name, encoding='utf-8') as input_file:\n",
    "        for line in input_file:\n",
    "            #* 0 1D 0/1 0.000000\n",
    "             #吾輩    名詞,代名詞,一般,*,*,*,吾輩,ワガハイ,ワガハイ\n",
    "            line_list=line.split()\n",
    "            #['吾輩', '名詞,代名詞,一般,*,*,*,吾輩,ワガハイ,ワガハイ']\n",
    "            if (line_list[0] == '*') | (line_list[0] == 'EOS'):\n",
    "                pass\n",
    "            else:\n",
    "                line_list = line_list[0].split(',') + line_list[1].split(',')\n",
    "                \n",
    "                _morph = Morph(surface=line_list[0], base=line_list[7],pos=line_list[1], pos1=line_list[2])\n",
    "                sentence.append(_morph)\n",
    "                \n",
    "                if _morph.is_end_of_sentence():\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "    return sentences\n",
    "\n",
    "morphed_sentences = make_morph_list('newkokoro.txt.cabocha')\n",
    "#[<__main__.Morph object at 0x0000014330DA8C88>, #文ごと\n",
    "for morph in morphed_sentences[0]:\n",
    "    print(str(morph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srcs: 0,dst: 9, morphs: (surface: 先生,base: 先生,pos: 名詞,pos1: 一般 / surface: は,base: は,pos: 助詞,pos1: 係助詞)\n",
      "srcs: 1,dst: 2, morphs: (surface: これら,base: これら,pos: 名詞,pos1: 代名詞 / surface: の,base: の,pos: 助詞,pos1: 連体化)\n",
      "srcs: 2,dst: 3, morphs: (surface: 墓標,base: 墓標,pos: 名詞,pos1: 一般 / surface: が,base: が,pos: 助詞,pos1: 格助詞)\n",
      "srcs: 3,dst: 5, morphs: (surface: 現,base: 現,pos: 接頭詞,pos1: 名詞接続 / surface: わす,base: わする,pos: 動詞,pos1: 自立)\n",
      "srcs: 4,dst: 5, morphs: (surface: 人種,base: 人種,pos: 名詞,pos1: 一般 / surface: 々,base: 々,pos: 記号,pos1: 一般 / surface: の,base: の,pos: 助詞,pos1: 連体化)\n",
      "srcs: 5,dst: 9, morphs: (surface: 様式,base: 様式,pos: 名詞,pos1: 一般 / surface: に対して,base: に対して,pos: 助詞,pos1: 格助詞 / surface: 、,base: 、,pos: 記号,pos1: 読点)\n",
      "srcs: 6,dst: 9, morphs: (surface: 私,base: 私,pos: 名詞,pos1: 代名詞 / surface: ほど,base: ほど,pos: 助詞,pos1: 副助詞 / surface: に,base: に,pos: 助詞,pos1: 格助詞)\n",
      "srcs: 7,dst: 8, morphs: (surface: 滑稽,base: 滑稽,pos: 名詞,pos1: 一般 / surface: も,base: も,pos: 助詞,pos1: 係助詞)\n",
      "srcs: 8,dst: 9, morphs: (surface: アイロニー,base: アイロニー,pos: 名詞,pos1: 一般 / surface: も,base: も,pos: 助詞,pos1: 係助詞)\n",
      "srcs: 9,dst: 33, morphs: (surface: 認め,base: 認める,pos: 動詞,pos1: 自立 / surface: て,base: てる,pos: 動詞,pos1: 非自立 / surface: ない,base: ない,pos: 助動詞,pos1: * / surface: らしかっ,base: らしい,pos: 助動詞,pos1: * / surface: た,base: た,pos: 助動詞,pos1: * / surface: 。,base: 。,pos: 記号,pos1: 句点)\n"
     ]
    }
   ],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, morphs:list, dst:str, srcs:str) ->None:\n",
    "#形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），\n",
    "#係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つ\n",
    "        self.morphs = morphs\n",
    "        self.dst = int(dst.strip(\"D\"))\n",
    "        self.srcs = int(srcs)\n",
    "    def join_morphs(self) -> str:\n",
    "        return ''.join([_motph.surface for _motph in self.morphs if _morph.pos != '記号'])\n",
    "    def __str__(self) ->str:\n",
    "        return 'srcs: {},dst: {}, morphs: ({})'.format(self.srcs, self.dst,\\\n",
    "                            ' / '.join([str(_morph) for _morph in self.morphs]))\n",
    "    #morphs当初は空っぽ\n",
    "\n",
    "def make_chunk_list(analyzed_file_name: str) ->list:\n",
    "    \"\"\"\n",
    "    係り受けした文章ファイル→chunkオブジェクトのリスト\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    _chunk = None\n",
    "    count = -1\n",
    "    with open(analyzed_file_name, encoding='utf-8')as input_file:\n",
    "         for line in input_file:  \n",
    "            line_list = line.split()\n",
    "            if line_list[0] == '*':\n",
    "                if _chunk is not None:\n",
    "                    sentence.append(_chunk)\n",
    "                _chunk = Chunk(morphs=[], dst=line_list[2], srcs=line_list[1])\n",
    "            elif line_list[0] == 'EOS':\n",
    "                break\n",
    "            else:\n",
    "                #print(line_list)\n",
    "                line_list = line_list[0].split(',') + line_list[1].split(',')\n",
    "                #print(line_list)\n",
    "                _morph = Morph(surface=line_list[0], base=line_list[7], \\\n",
    "                              pos=line_list[1], pos1=line_list[2])\n",
    "                #print(count,_morph)\n",
    "                #print(count,_chunk.morphs)\n",
    "                _chunk.morphs.append(_morph)\n",
    "                #print(count,_chunk.morphs)\n",
    "                #if line_list[0] == '。' and input_file[count-1]!='」':\n",
    "                if line_list[0] == '。':\n",
    "                    if _chunk is not None:\n",
    "                        sentence.append(_chunk)\n",
    "                    if len(sentence) > 0:\n",
    "                        sentences.append(sentence)\n",
    "                    _chunk = None\n",
    "                    sentence = []\n",
    "                        \n",
    "    return sentences\n",
    "chunked_sentences = make_chunk_list('newkokoro.txt.cabocha')\n",
    "for chunk in chunked_sentences[0]: \n",
    "    print(str(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-197-4920083e5fc8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-197-4920083e5fc8>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    2093 surface:なら,base:だ\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def is_valid_chunk(_chunk, sentence):\n",
    "    return _chunk.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
